{"cells":[{"cell_type":"markdown","metadata":{"id":"vSDcy7tESHov"},"source":["# veuillez trouvez les donnes utilisez dans le reposotery:\n","https://github.com/siscotahir/Data.git\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rwJfoT6OSte4"},"outputs":[],"source":["!git clone https://github.com/siscotahir/Data.git"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"YN3cx-D6OaKF"},"outputs":[],"source":["!pip install -U ultralytics\n","\n","import numpy as np\n","import torch\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GwI-LTVvWZy7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RiaUKsWRKZmC"},"outputs":[],"source":["from ultralytics import YOLO\n","model = YOLO(\"yolov8n.pt\")\n","model.info()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"9b1ae6b6"},"outputs":[],"source":["import os\n","\n","# Regarde ce qu'il y a dans /content\n","print(\"Contenu de /content :\")\n","print(os.listdir(\"/content\"))\n","\n","# Assuming your folder is in Google Drive after mounting\n","dataset_dir = \"/content/Data\"\n","\n","if os.path.exists(dataset_dir):\n","    print(f\"\\nContenu du dataset √† '{dataset_dir}' :\")\n","    for root, dirs, files in os.walk(dataset_dir):\n","        level = root.replace(dataset_dir, '').count(os.sep)\n","        indent = '  ' * level\n","        print(f\"{indent}{os.path.basename(root)}/\")\n","        subindent = '  ' * (level + 1)\n","        for f in files:\n","            print(f\"{subindent}{f}\")\n","else:\n","    print(f\"\\nLe dossier du dataset '{dataset_dir}' n'a pas √©t√© trouv√©. Veuillez v√©rifier le chemin.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v1gVjc5TMAta"},"outputs":[],"source":["yaml_text = \"\"\"\n","# Chemin racine du dataset\n","path: /content/Data\n","\n","# Sous-dossiers images\n","train: train/images\n","val: valid/images\n","test: test/images\n","\n","# Nombre de classes\n","nc: 7\n","\n","# Noms de classes (dans l'ordre des ID des labels)\n","names:\n","  0: personne\n","  1: lunettes\n","  2: casque\n","  3: sans_lunettes\n","  4: sans_casque\n","  5: sans_gilet\n","  6: gilet\n","\"\"\"\n","\n","yaml_path = \"/content/Data/data.yaml\"  # Changed to a file path\n","with open(yaml_path, \"w\") as f:\n","    f.write(yaml_text)\n","\n","print(\"Fichier YAML cr√©√©:\\n\")\n","print(open(yaml_path).read())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ukx6OVXsc99R"},"outputs":[],"source":["import os\n","os.environ[\"WANDB_MODE\"] = \"disabled\"  # Change to \"disabled\" to completely prevent W\u0026B from running\n","# Optionnel: emp√™che wandb d'essayer des connexions r√©seau\n","os.environ[\"WANDB_SILENT\"] = \"true\"\n","print(\"WANDB_MODE =\", os.environ.get(\"WANDB_MODE\"))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"xpDjo1XaNlgi"},"outputs":[{"name":"stdout","output_type":"stream","text":["New https://pypi.org/project/ultralytics/8.3.235 available üòÉ Update with 'pip install -U ultralytics'\n","Ultralytics 8.3.0 üöÄ Python-3.12.12 torch-2.9.0+cu126 CPU (Intel Xeon 2.20GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/Data/data.yaml, epochs=50, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=RUN, name=yolo_classes, exist_ok=True, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=RUN/yolo_classes\n","Overriding model.yaml nc=80 with nc=7\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    432037  ultralytics.nn.modules.head.Detect           [7, [64, 128, 256]]           \n","Model summary: 249 layers, 2,691,573 parameters, 2,691,557 gradients, 6.9 GFLOPs\n","\n","Transferred 313/391 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir RUN/yolo_classes', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n"]},{"name":"stderr","output_type":"stream","text":["\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Data/train/labels.cache... 1428 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1428/1428 [00:00\u003c?, ?it/s]"]},{"name":"stdout","output_type":"stream","text":["WARNING ‚ö†Ô∏è Box and segment counts should be equal, but got len(segments) = 23, len(boxes) = 8382. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n"]},{"name":"stderr","output_type":"stream","text":["\n","/usr/local/lib/python3.12/dist-packages/ultralytics/data/augment.py:1850: UserWarning: Argument(s) 'quality_lower' are not valid for transform ImageCompression\n","  A.ImageCompression(quality_lower=75, p=0.0),\n","/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n","  warnings.warn(warn_msg)\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Data/valid/labels.cache... 403 images, 0 backgrounds, 0 corrupt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 403/403 [00:00\u003c?, ?it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Plotting labels to RUN/yolo_classes/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000909, momentum=0.9) with parameter groups 63 weight(decay=0.0), 70 weight(decay=0.0005), 69 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ‚úÖ\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mRUN/yolo_classes\u001b[0m\n","Starting training for 50 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       1/50         0G      1.413       2.88      1.457         62        640: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90/90 [21:12\u003c00:00, 14.14s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 13/13 [01:41\u003c00:00,  7.78s/it]"]},{"name":"stdout","output_type":"stream","text":["                   all        403       2365      0.913      0.278      0.314      0.188\n"]},{"name":"stderr","output_type":"stream","text":["\n"]},{"name":"stdout","output_type":"stream","text":["\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"]},{"name":"stderr","output_type":"stream","text":["       2/50         0G      1.414      1.792      1.449        262        640:  30%|‚ñà‚ñà‚ñà       | 27/90 [06:31\u003c15:02, 14.32s/it]"]}],"source":["from ultralytics import YOLO\n","import os\n","\n","# WANDB_MODE is already set in a previous cell, removed redundant line here\n","\n","model = YOLO(\"yolov8n.pt\")\n","results = model.train(\n","    data=yaml_path,\n","    epochs=50,\n","    imgsz=640,\n","    batch=16,\n","    project=\"RUN\",\n","    name=\"yolo_classes\",\n","    exist_ok=True\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"139hHW4soFIF"},"outputs":[],"source":["from ultralytics import YOLO\n","import os\n","\n","runs_dir = \"/content/RUN/yolo_classes\"  # Corrected path\n","weights_dir = os.path.join(runs_dir, \"weights\")\n","best_model_path = os.path.join(weights_dir, \"best.pt\")\n","\n","print(\"Dossier du run :\", runs_dir)\n","print(\"Fichiers dans weights :\", os.listdir(weights_dir))\n","print(\"Chemin du meilleur mod√®le :\", best_model_path)\n","\n","model = YOLO(best_model_path)\n","print(\"Classes apprises :\", model.names)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R3JU0hI9pAyD"},"outputs":[],"source":["from IPython.display import Image, display\n","\n","results_png = os.path.join(runs_dir, \"results.png\")\n","\n","\n","print(\"Courbes d'entra√Ænement :\")\n","display(Image(filename=results_png))\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRc0X5H4w887"},"outputs":[],"source":["from IPython.display import Image, display\n","conf_matrix_png = os.path.join(runs_dir, \"confusion_matrix.png\")\n","print(\"Matrice de confusion :\")\n","display(Image(filename=conf_matrix_png))"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"G3E-M1VcxxtA"},"outputs":[],"source":["# Petit script compact - pr√©c, rappel, F1 par classe\n","import glob, os, torch, numpy as np\n","from ultralytics import YOLO\n","from PIL import Image\n","\n","best_model_path = \"/content/RUN/yolo_classes/weights/best.pt\"\n","val_images_dir = \"/content/Data/valid/images\"\n","val_labels_dir = \"/content/Data/valid/labels\"\n","conf_thresh = 0.001\n","iou_thresh = 0.5\n","\n","model = YOLO(best_model_path)\n","n = len(model.names)\n","TP = [0]*n; FP=[0]*n; FN=[0]*n; GT=[0]*n\n","\n","def iou(a,b):\n","    xa1,ya1,xa2,ya2 = a; xb1,yb1,xb2,yb2 = b\n","    xi1, yi1 = max(xa1,xb1), max(ya1,yb1)\n","    xi2, yi2 = min(xa2,xb2), min(ya2,yb2)\n","    inter = max(0, xi2-xi1) * max(0, yi2-yi1)\n","    union = max(0, xa2-xa1)*max(0, ya2-ya1) + max(0, xb2-xb1)*max(0, yb2-xb1) - inter\n","    return inter/(union+1e-9)\n","\n","def yolo_to_xyxy(line, W,H):\n","    c,xc,yc,w,h = line.split()\n","    c=int(c); xc, yc, w, h = map(float,(xc,yc,w,h))\n","    x1=(xc-w/2)*W; y1=(yc-h/2)*H; x2=(xc+w/2)*W; y2=(yc+h/2)*H\n","    return c,[x1,y1,x2,y2]\n","\n","for img_path in sorted(glob.glob(os.path.join(val_images_dir,\"*\"))):\n","    W,H = Image.open(img_path).size\n","    # ground-truth\n","    lab = os.path.join(val_labels_dir, os.path.basename(img_path).rsplit('.',1)[0]+\".txt\")\n","    gts = []\n","    if os.path.exists(lab):\n","        for L in open(lab):\n","            cls,box = yolo_to_xyxy(L.strip(),W,H); gts.append((cls,box)); GT[cls]+=1\n","    preds = model.predict(source=img_path, conf=conf_thresh, save=False)[0]\n","    if hasattr(preds, \"boxes\") and len(preds.boxes)\u003e0:\n","        p_boxes = preds.boxes.xyxy.cpu().numpy()\n","        p_cls = preds.boxes.cls.cpu().numpy().astype(int)\n","        p_scores = preds.boxes.conf.cpu().numpy()\n","    else:\n","        p_boxes=np.zeros((0,4)); p_cls=np.array([]); p_scores=np.array([])\n","    # matching greedy per class by score\n","    for cls in range(n):\n","        gt_boxes = [b for c,b in gts if c==cls]\n","        pred_idx = np.where(p_cls==cls)[0]\n","        if len(pred_idx)==0:\n","            FN[cls]+=len(gt_boxes); continue\n","        matched = set()\n","        for i in sorted(pred_idx, key=lambda i: -p_scores[i]):\n","            pb = p_boxes[i]\n","            best_i, best_iou = -1, 0\n","            for j,gb in enumerate(gt_boxes):\n","                if j in matched: continue\n","                iou_val = iou(pb, gb)\n","                if iou_val\u003ebest_iou: best_iou=iou_val; best_i=j\n","            if best_i\u003e=0 and best_iou\u003e=iou_thresh:\n","                TP[cls]+=1; matched.add(best_i)\n","            else:\n","                FP[cls]+=1\n","        FN[cls]+= (len(gt_boxes)-len(matched))\n","\n","# afficher r√©sultats\n","for idx,name in model.names.items():\n","    tp,fp,fn = TP[idx],FP[idx],FN[idx]\n","    prec = tp/(tp+fp) if tp+fp\u003e0 else 0\n","    rec  = tp/(tp+fn) if tp+fn\u003e0 else 0\n","    f1 = 2*prec*rec/(prec+rec) if prec+rec\u003e0 else 0\n","    print(f\"{idx} {name}: GT={GT[idx]:3d} TP={tp:3d} FP={fp:3d} FN={fn:3d}  Prec={prec:.3f}  Rec={rec:.3f}  F1={f1:.3f}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b7wJ4Gstpjfq"},"outputs":[],"source":["from google.colab import files\n","import os\n","\n","test_dir = \"/content/Data\"\n","os.makedirs(test_dir, exist_ok=True)\n","\n","uploaded = files.upload()  # choisis une ou plusieurs images\n","for name, data in uploaded.items():\n","    with open(os.path.join(test_dir, name), \"wb\") as f:\n","        f.write(data)\n","print(\"Images de test enregistr√©es dans :\", test_dir)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GLLVcDsjtCXw"},"outputs":[],"source":["from IPython.display import Image, display\n","import glob\n","\n","# pr√©dire uniquement au-dessus d'une certaine confiance\n","results = model.predict(\n","    source=test_dir,\n","    conf=0.4,       # seuil √† ajuster\n","    save=True\n",")\n","\n","pred_dir = results[0].save_dir\n","print(\"Images annot√©es sauvegard√©es dans :\", pred_dir)\n","\n","for img_path in glob.glob(os.path.join(pred_dir, \"*\")):\n","    display(Image(filename=img_path))\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyOTe1dZXvA8yzq8GhTreqGE","gpuType":"T4","mount_file_id":"1t9YN33h4w2CnR1vgxMKnpkZjM4ejilqf","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}